{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b80f3b3-15a4-450a-9fec-911e64d9e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#program 5 - Build an artificial neural network by implementing the back propagation algorithm and test the same using appropriate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d86813c-ba91-4b91-8968-3c84e8902c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "iteration : 0  ::::::  [[ 0.03720184 -0.89287538]]\n",
      "######## output ######### [[0.96279816 0.89287538]]\n",
      "***********************************************\n",
      "iteration : 1  ::::::  [[ 0.03721304 -0.89166002]]\n",
      "######## output ######### [[0.96278696 0.89166002]]\n",
      "***********************************************\n",
      "iteration : 2  ::::::  [[ 0.03722431 -0.89042272]]\n",
      "######## output ######### [[0.96277569 0.89042272]]\n",
      "***********************************************\n",
      "iteration : 3  ::::::  [[ 0.03723565 -0.88916301]]\n",
      "######## output ######### [[0.96276435 0.88916301]]\n",
      "***********************************************\n",
      "iteration : 4  ::::::  [[ 0.03724707 -0.88788039]]\n",
      "######## output ######### [[0.96275293 0.88788039]]\n",
      "***********************************************\n",
      "iteration : 5  ::::::  [[ 0.03725855 -0.88657436]]\n",
      "######## output ######### [[0.96274145 0.88657436]]\n",
      "***********************************************\n",
      "iteration : 6  ::::::  [[ 0.0372701  -0.88524442]]\n",
      "######## output ######### [[0.9627299  0.88524442]]\n",
      "***********************************************\n",
      "iteration : 7  ::::::  [[ 0.03728172 -0.88389004]]\n",
      "######## output ######### [[0.96271828 0.88389004]]\n",
      "***********************************************\n",
      "iteration : 8  ::::::  [[ 0.0372934  -0.88251069]]\n",
      "######## output ######### [[0.9627066  0.88251069]]\n",
      "***********************************************\n",
      "iteration : 9  ::::::  [[ 0.03730515 -0.88110582]]\n",
      "######## output ######### [[0.96269485 0.88110582]]\n",
      "***********************************************\n",
      "iteration : 10  ::::::  [[ 0.03731695 -0.87967489]]\n",
      "######## output ######### [[0.96268305 0.87967489]]\n",
      "***********************************************\n",
      "iteration : 11  ::::::  [[ 0.03732882 -0.87821732]]\n",
      "######## output ######### [[0.96267118 0.87821732]]\n",
      "***********************************************\n",
      "iteration : 12  ::::::  [[ 0.03734075 -0.87673254]]\n",
      "######## output ######### [[0.96265925 0.87673254]]\n",
      "***********************************************\n",
      "iteration : 13  ::::::  [[ 0.03735273 -0.87521997]]\n",
      "######## output ######### [[0.96264727 0.87521997]]\n",
      "***********************************************\n",
      "iteration : 14  ::::::  [[ 0.03736477 -0.87367901]]\n",
      "######## output ######### [[0.96263523 0.87367901]]\n",
      "***********************************************\n",
      "iteration : 15  ::::::  [[ 0.03737686 -0.87210905]]\n",
      "######## output ######### [[0.96262314 0.87210905]]\n",
      "***********************************************\n",
      "iteration : 16  ::::::  [[ 0.037389   -0.87050948]]\n",
      "######## output ######### [[0.962611   0.87050948]]\n",
      "***********************************************\n",
      "iteration : 17  ::::::  [[ 0.03740119 -0.86887966]]\n",
      "######## output ######### [[0.96259881 0.86887966]]\n",
      "***********************************************\n",
      "iteration : 18  ::::::  [[ 0.03741343 -0.86721896]]\n",
      "######## output ######### [[0.96258657 0.86721896]]\n",
      "***********************************************\n",
      "iteration : 19  ::::::  [[ 0.0374257  -0.86552673]]\n",
      "######## output ######### [[0.9625743  0.86552673]]\n",
      "***********************************************\n",
      "iteration : 20  ::::::  [[ 0.03743802 -0.86380231]]\n",
      "######## output ######### [[0.96256198 0.86380231]]\n",
      "***********************************************\n",
      "iteration : 21  ::::::  [[ 0.03745037 -0.86204503]]\n",
      "######## output ######### [[0.96254963 0.86204503]]\n",
      "***********************************************\n",
      "iteration : 22  ::::::  [[ 0.03746276 -0.86025422]]\n",
      "######## output ######### [[0.96253724 0.86025422]]\n",
      "***********************************************\n",
      "iteration : 23  ::::::  [[ 0.03747517 -0.8584292 ]]\n",
      "######## output ######### [[0.96252483 0.8584292 ]]\n",
      "***********************************************\n",
      "iteration : 24  ::::::  [[ 0.03748761 -0.85656926]]\n",
      "######## output ######### [[0.96251239 0.85656926]]\n",
      "***********************************************\n",
      "iteration : 25  ::::::  [[ 0.03750008 -0.85467371]]\n",
      "######## output ######### [[0.96249992 0.85467371]]\n",
      "***********************************************\n",
      "iteration : 26  ::::::  [[ 0.03751257 -0.85274183]]\n",
      "######## output ######### [[0.96248743 0.85274183]]\n",
      "***********************************************\n",
      "iteration : 27  ::::::  [[ 0.03752507 -0.85077292]]\n",
      "######## output ######### [[0.96247493 0.85077292]]\n",
      "***********************************************\n",
      "iteration : 28  ::::::  [[ 0.03753758 -0.84876625]]\n",
      "######## output ######### [[0.96246242 0.84876625]]\n",
      "***********************************************\n",
      "iteration : 29  ::::::  [[ 0.0375501  -0.84672109]]\n",
      "######## output ######### [[0.9624499  0.84672109]]\n",
      "***********************************************\n",
      "iteration : 30  ::::::  [[ 0.03756262 -0.84463672]]\n",
      "######## output ######### [[0.96243738 0.84463672]]\n",
      "***********************************************\n",
      "iteration : 31  ::::::  [[ 0.03757514 -0.84251239]]\n",
      "######## output ######### [[0.96242486 0.84251239]]\n",
      "***********************************************\n",
      "iteration : 32  ::::::  [[ 0.03758766 -0.84034737]]\n",
      "######## output ######### [[0.96241234 0.84034737]]\n",
      "***********************************************\n",
      "iteration : 33  ::::::  [[ 0.03760016 -0.83814092]]\n",
      "######## output ######### [[0.96239984 0.83814092]]\n",
      "***********************************************\n",
      "iteration : 34  ::::::  [[ 0.03761264 -0.83589231]]\n",
      "######## output ######### [[0.96238736 0.83589231]]\n",
      "***********************************************\n",
      "iteration : 35  ::::::  [[ 0.0376251  -0.83360078]]\n",
      "######## output ######### [[0.9623749  0.83360078]]\n",
      "***********************************************\n",
      "iteration : 36  ::::::  [[ 0.03763754 -0.83126561]]\n",
      "######## output ######### [[0.96236246 0.83126561]]\n",
      "***********************************************\n",
      "iteration : 37  ::::::  [[ 0.03764994 -0.82888607]]\n",
      "######## output ######### [[0.96235006 0.82888607]]\n",
      "***********************************************\n",
      "iteration : 38  ::::::  [[ 0.0376623  -0.82646141]]\n",
      "######## output ######### [[0.9623377  0.82646141]]\n",
      "***********************************************\n",
      "iteration : 39  ::::::  [[ 0.03767462 -0.82399093]]\n",
      "######## output ######### [[0.96232538 0.82399093]]\n",
      "***********************************************\n",
      "iteration : 40  ::::::  [[ 0.03768688 -0.82147391]]\n",
      "######## output ######### [[0.96231312 0.82147391]]\n",
      "***********************************************\n",
      "iteration : 41  ::::::  [[ 0.03769909 -0.81890964]]\n",
      "######## output ######### [[0.96230091 0.81890964]]\n",
      "***********************************************\n",
      "iteration : 42  ::::::  [[ 0.03771122 -0.81629743]]\n",
      "######## output ######### [[0.96228878 0.81629743]]\n",
      "***********************************************\n",
      "iteration : 43  ::::::  [[ 0.03772329 -0.81363662]]\n",
      "######## output ######### [[0.96227671 0.81363662]]\n",
      "***********************************************\n",
      "iteration : 44  ::::::  [[ 0.03773528 -0.81092653]]\n",
      "######## output ######### [[0.96226472 0.81092653]]\n",
      "***********************************************\n",
      "iteration : 45  ::::::  [[ 0.03774717 -0.80816652]]\n",
      "######## output ######### [[0.96225283 0.80816652]]\n",
      "***********************************************\n",
      "iteration : 46  ::::::  [[ 0.03775898 -0.80535598]]\n",
      "######## output ######### [[0.96224102 0.80535598]]\n",
      "***********************************************\n",
      "iteration : 47  ::::::  [[ 0.03777068 -0.80249431]]\n",
      "######## output ######### [[0.96222932 0.80249431]]\n",
      "***********************************************\n",
      "iteration : 48  ::::::  [[ 0.03778227 -0.79958094]]\n",
      "######## output ######### [[0.96221773 0.79958094]]\n",
      "***********************************************\n",
      "iteration : 49  ::::::  [[ 0.03779374 -0.79661532]]\n",
      "######## output ######### [[0.96220626 0.79661532]]\n",
      "***********************************************\n",
      "iteration : 5951  ::::::  [[ 0.01877364 -0.02363019]]\n",
      "######## output ######### [[0.98122636 0.02363019]]\n",
      "***********************************************\n",
      "iteration : 5952  ::::::  [[ 0.01877247 -0.02362797]]\n",
      "######## output ######### [[0.98122753 0.02362797]]\n",
      "***********************************************\n",
      "iteration : 5953  ::::::  [[ 0.01877131 -0.02362575]]\n",
      "######## output ######### [[0.98122869 0.02362575]]\n",
      "***********************************************\n",
      "iteration : 5954  ::::::  [[ 0.01877015 -0.02362354]]\n",
      "######## output ######### [[0.98122985 0.02362354]]\n",
      "***********************************************\n",
      "iteration : 5955  ::::::  [[ 0.01876899 -0.02362132]]\n",
      "######## output ######### [[0.98123101 0.02362132]]\n",
      "***********************************************\n",
      "iteration : 5956  ::::::  [[ 0.01876783 -0.0236191 ]]\n",
      "######## output ######### [[0.98123217 0.0236191 ]]\n",
      "***********************************************\n",
      "iteration : 5957  ::::::  [[ 0.01876666 -0.02361688]]\n",
      "######## output ######### [[0.98123334 0.02361688]]\n",
      "***********************************************\n",
      "iteration : 5958  ::::::  [[ 0.0187655  -0.02361467]]\n",
      "######## output ######### [[0.9812345  0.02361467]]\n",
      "***********************************************\n",
      "iteration : 5959  ::::::  [[ 0.01876434 -0.02361245]]\n",
      "######## output ######### [[0.98123566 0.02361245]]\n",
      "***********************************************\n",
      "iteration : 5960  ::::::  [[ 0.01876318 -0.02361024]]\n",
      "######## output ######### [[0.98123682 0.02361024]]\n",
      "***********************************************\n",
      "iteration : 5961  ::::::  [[ 0.01876202 -0.02360802]]\n",
      "######## output ######### [[0.98123798 0.02360802]]\n",
      "***********************************************\n",
      "iteration : 5962  ::::::  [[ 0.01876086 -0.02360581]]\n",
      "######## output ######### [[0.98123914 0.02360581]]\n",
      "***********************************************\n",
      "iteration : 5963  ::::::  [[ 0.0187597 -0.0236036]]\n",
      "######## output ######### [[0.9812403 0.0236036]]\n",
      "***********************************************\n",
      "iteration : 5964  ::::::  [[ 0.01875854 -0.02360139]]\n",
      "######## output ######### [[0.98124146 0.02360139]]\n",
      "***********************************************\n",
      "iteration : 5965  ::::::  [[ 0.01875738 -0.02359917]]\n",
      "######## output ######### [[0.98124262 0.02359917]]\n",
      "***********************************************\n",
      "iteration : 5966  ::::::  [[ 0.01875622 -0.02359696]]\n",
      "######## output ######### [[0.98124378 0.02359696]]\n",
      "***********************************************\n",
      "iteration : 5967  ::::::  [[ 0.01875506 -0.02359475]]\n",
      "######## output ######### [[0.98124494 0.02359475]]\n",
      "***********************************************\n",
      "iteration : 5968  ::::::  [[ 0.0187539  -0.02359254]]\n",
      "######## output ######### [[0.9812461  0.02359254]]\n",
      "***********************************************\n",
      "iteration : 5969  ::::::  [[ 0.01875274 -0.02359033]]\n",
      "######## output ######### [[0.98124726 0.02359033]]\n",
      "***********************************************\n",
      "iteration : 5970  ::::::  [[ 0.01875159 -0.02358812]]\n",
      "######## output ######### [[0.98124841 0.02358812]]\n",
      "***********************************************\n",
      "iteration : 5971  ::::::  [[ 0.01875043 -0.02358592]]\n",
      "######## output ######### [[0.98124957 0.02358592]]\n",
      "***********************************************\n",
      "iteration : 5972  ::::::  [[ 0.01874927 -0.02358371]]\n",
      "######## output ######### [[0.98125073 0.02358371]]\n",
      "***********************************************\n",
      "iteration : 5973  ::::::  [[ 0.01874811 -0.0235815 ]]\n",
      "######## output ######### [[0.98125189 0.0235815 ]]\n",
      "***********************************************\n",
      "iteration : 5974  ::::::  [[ 0.01874695 -0.02357929]]\n",
      "######## output ######### [[0.98125305 0.02357929]]\n",
      "***********************************************\n",
      "iteration : 5975  ::::::  [[ 0.0187458  -0.02357709]]\n",
      "######## output ######### [[0.9812542  0.02357709]]\n",
      "***********************************************\n",
      "iteration : 5976  ::::::  [[ 0.01874464 -0.02357488]]\n",
      "######## output ######### [[0.98125536 0.02357488]]\n",
      "***********************************************\n",
      "iteration : 5977  ::::::  [[ 0.01874348 -0.02357268]]\n",
      "######## output ######### [[0.98125652 0.02357268]]\n",
      "***********************************************\n",
      "iteration : 5978  ::::::  [[ 0.01874232 -0.02357048]]\n",
      "######## output ######### [[0.98125768 0.02357048]]\n",
      "***********************************************\n",
      "iteration : 5979  ::::::  [[ 0.01874117 -0.02356827]]\n",
      "######## output ######### [[0.98125883 0.02356827]]\n",
      "***********************************************\n",
      "iteration : 5980  ::::::  [[ 0.01874001 -0.02356607]]\n",
      "######## output ######### [[0.98125999 0.02356607]]\n",
      "***********************************************\n",
      "iteration : 5981  ::::::  [[ 0.01873886 -0.02356387]]\n",
      "######## output ######### [[0.98126114 0.02356387]]\n",
      "***********************************************\n",
      "iteration : 5982  ::::::  [[ 0.0187377  -0.02356167]]\n",
      "######## output ######### [[0.9812623  0.02356167]]\n",
      "***********************************************\n",
      "iteration : 5983  ::::::  [[ 0.01873654 -0.02355946]]\n",
      "######## output ######### [[0.98126346 0.02355946]]\n",
      "***********************************************\n",
      "iteration : 5984  ::::::  [[ 0.01873539 -0.02355726]]\n",
      "######## output ######### [[0.98126461 0.02355726]]\n",
      "***********************************************\n",
      "iteration : 5985  ::::::  [[ 0.01873423 -0.02355506]]\n",
      "######## output ######### [[0.98126577 0.02355506]]\n",
      "***********************************************\n",
      "iteration : 5986  ::::::  [[ 0.01873308 -0.02355286]]\n",
      "######## output ######### [[0.98126692 0.02355286]]\n",
      "***********************************************\n",
      "iteration : 5987  ::::::  [[ 0.01873192 -0.02355067]]\n",
      "######## output ######### [[0.98126808 0.02355067]]\n",
      "***********************************************\n",
      "iteration : 5988  ::::::  [[ 0.01873077 -0.02354847]]\n",
      "######## output ######### [[0.98126923 0.02354847]]\n",
      "***********************************************\n",
      "iteration : 5989  ::::::  [[ 0.01872961 -0.02354627]]\n",
      "######## output ######### [[0.98127039 0.02354627]]\n",
      "***********************************************\n",
      "iteration : 5990  ::::::  [[ 0.01872846 -0.02354407]]\n",
      "######## output ######### [[0.98127154 0.02354407]]\n",
      "***********************************************\n",
      "iteration : 5991  ::::::  [[ 0.0187273  -0.02354188]]\n",
      "######## output ######### [[0.9812727  0.02354188]]\n",
      "***********************************************\n",
      "iteration : 5992  ::::::  [[ 0.01872615 -0.02353968]]\n",
      "######## output ######### [[0.98127385 0.02353968]]\n",
      "***********************************************\n",
      "iteration : 5993  ::::::  [[ 0.018725   -0.02353749]]\n",
      "######## output ######### [[0.981275   0.02353749]]\n",
      "***********************************************\n",
      "iteration : 5994  ::::::  [[ 0.01872384 -0.02353529]]\n",
      "######## output ######### [[0.98127616 0.02353529]]\n",
      "***********************************************\n",
      "iteration : 5995  ::::::  [[ 0.01872269 -0.0235331 ]]\n",
      "######## output ######### [[0.98127731 0.0235331 ]]\n",
      "***********************************************\n",
      "iteration : 5996  ::::::  [[ 0.01872154 -0.0235309 ]]\n",
      "######## output ######### [[0.98127846 0.0235309 ]]\n",
      "***********************************************\n",
      "iteration : 5997  ::::::  [[ 0.01872038 -0.02352871]]\n",
      "######## output ######### [[0.98127962 0.02352871]]\n",
      "***********************************************\n",
      "iteration : 5998  ::::::  [[ 0.01871923 -0.02352652]]\n",
      "######## output ######### [[0.98128077 0.02352652]]\n",
      "***********************************************\n",
      "iteration : 5999  ::::::  [[ 0.01871808 -0.02352433]]\n",
      "######## output ######### [[0.98128192 0.02352433]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def sigmoid (layer):\n",
    "    return 1 / (1 + np.exp(-layer))\n",
    "\n",
    "def gradient(layer):\n",
    "    return layer * (1 - layer)\n",
    "    \n",
    "ipNeurons = 2\n",
    "hiddenLayerNeurons = 4\n",
    "opNeurons = 2\n",
    "iterations = 6000\n",
    "\n",
    "ip = np.random.randint(1,5,ipNeurons)\n",
    "op = np.array([1.0,0.0])\n",
    "hidden_layer = np.random.rand(1, hiddenLayerNeurons)\n",
    "\n",
    "hidden_bias = np.random.rand(1, hiddenLayerNeurons)\n",
    "op_bias = np.random.rand(1, opNeurons)\n",
    "hidden_weights = np.random.rand(ipNeurons, hiddenLayerNeurons)\n",
    "op_weights = np.random.rand(hiddenLayerNeurons, opNeurons)\n",
    "\n",
    "for i in range(iterations):\n",
    "    hidden_layer = np.dot(ip, hidden_weights)\n",
    "    hidden_layer = sigmoid(hidden_layer + hidden_bias)\n",
    "    output_layer = np.dot(hidden_layer, op_weights)\n",
    "    output_layer = sigmoid(output_layer + op_bias)\n",
    "\n",
    "    error = (op - output_layer)\n",
    "    gradient_op_layer = gradient(output_layer)\n",
    "    error_terms_output = gradient_op_layer * error\n",
    "    error_terms_hidden = gradient(hidden_layer) * np.dot(error_terms_output, op_weights.T)\n",
    "\n",
    "    gradient_hidden_weights = np.dot(ip.reshape(ipNeurons, 1), error_terms_hidden.reshape(1, hiddenLayerNeurons))\n",
    "    gradient_output_weights = np.dot(hidden_layer.reshape(hiddenLayerNeurons, 1), error_terms_output.reshape(1, opNeurons))\n",
    "    \n",
    "    hidden_weights = hidden_weights + 0.05 * gradient_hidden_weights\n",
    "    op_weights = op_weights + 0.05 * gradient_output_weights\n",
    "\n",
    "    if i < 50 or i > iterations - 50:\n",
    "        print('***********************************************')\n",
    "        print('iteration :',i,' :::::: ', error)\n",
    "        print('######## output #########', output_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
