{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b80f3b3-15a4-450a-9fec-911e64d9e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#program 5 - Build an artificial neural network by implementing the back propagation algorithm and test the same using appropriate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d86813c-ba91-4b91-8968-3c84e8902c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "iteration : 0  ::::::  [[ 0.0763003  -0.95923952]]\n",
      "######## output ######### [[0.9236997  0.95923952]]\n",
      "***********************************************\n",
      "iteration : 1  ::::::  [[ 0.07623878 -0.95896966]]\n",
      "######## output ######### [[0.92376122 0.95896966]]\n",
      "***********************************************\n",
      "iteration : 2  ::::::  [[ 0.07617746 -0.95869648]]\n",
      "######## output ######### [[0.92382254 0.95869648]]\n",
      "***********************************************\n",
      "iteration : 3  ::::::  [[ 0.07611634 -0.95841992]]\n",
      "######## output ######### [[0.92388366 0.95841992]]\n",
      "***********************************************\n",
      "iteration : 4  ::::::  [[ 0.07605541 -0.95813991]]\n",
      "######## output ######### [[0.92394459 0.95813991]]\n",
      "***********************************************\n",
      "iteration : 5  ::::::  [[ 0.07599469 -0.95785639]]\n",
      "######## output ######### [[0.92400531 0.95785639]]\n",
      "***********************************************\n",
      "iteration : 6  ::::::  [[ 0.07593416 -0.95756931]]\n",
      "######## output ######### [[0.92406584 0.95756931]]\n",
      "***********************************************\n",
      "iteration : 7  ::::::  [[ 0.07587383 -0.9572786 ]]\n",
      "######## output ######### [[0.92412617 0.9572786 ]]\n",
      "***********************************************\n",
      "iteration : 8  ::::::  [[ 0.07581369 -0.95698419]]\n",
      "######## output ######### [[0.92418631 0.95698419]]\n",
      "***********************************************\n",
      "iteration : 9  ::::::  [[ 0.07575375 -0.95668602]]\n",
      "######## output ######### [[0.92424625 0.95668602]]\n",
      "***********************************************\n",
      "iteration : 10  ::::::  [[ 0.07569401 -0.95638401]]\n",
      "######## output ######### [[0.92430599 0.95638401]]\n",
      "***********************************************\n",
      "iteration : 11  ::::::  [[ 0.07563446 -0.95607811]]\n",
      "######## output ######### [[0.92436554 0.95607811]]\n",
      "***********************************************\n",
      "iteration : 12  ::::::  [[ 0.07557511 -0.95576822]]\n",
      "######## output ######### [[0.92442489 0.95576822]]\n",
      "***********************************************\n",
      "iteration : 13  ::::::  [[ 0.07551595 -0.9554543 ]]\n",
      "######## output ######### [[0.92448405 0.9554543 ]]\n",
      "***********************************************\n",
      "iteration : 14  ::::::  [[ 0.07545699 -0.95513625]]\n",
      "######## output ######### [[0.92454301 0.95513625]]\n",
      "***********************************************\n",
      "iteration : 15  ::::::  [[ 0.07539822 -0.954814  ]]\n",
      "######## output ######### [[0.92460178 0.954814  ]]\n",
      "***********************************************\n",
      "iteration : 16  ::::::  [[ 0.07533965 -0.95448748]]\n",
      "######## output ######### [[0.92466035 0.95448748]]\n",
      "***********************************************\n",
      "iteration : 17  ::::::  [[ 0.07528127 -0.9541566 ]]\n",
      "######## output ######### [[0.92471873 0.9541566 ]]\n",
      "***********************************************\n",
      "iteration : 18  ::::::  [[ 0.07522308 -0.95382127]]\n",
      "######## output ######### [[0.92477692 0.95382127]]\n",
      "***********************************************\n",
      "iteration : 19  ::::::  [[ 0.07516509 -0.95348143]]\n",
      "######## output ######### [[0.92483491 0.95348143]]\n",
      "***********************************************\n",
      "iteration : 20  ::::::  [[ 0.07510729 -0.95313697]]\n",
      "######## output ######### [[0.92489271 0.95313697]]\n",
      "***********************************************\n",
      "iteration : 21  ::::::  [[ 0.07504968 -0.95278782]]\n",
      "######## output ######### [[0.92495032 0.95278782]]\n",
      "***********************************************\n",
      "iteration : 22  ::::::  [[ 0.07499227 -0.95243387]]\n",
      "######## output ######### [[0.92500773 0.95243387]]\n",
      "***********************************************\n",
      "iteration : 23  ::::::  [[ 0.07493504 -0.95207505]]\n",
      "######## output ######### [[0.92506496 0.95207505]]\n",
      "***********************************************\n",
      "iteration : 24  ::::::  [[ 0.07487801 -0.95171124]]\n",
      "######## output ######### [[0.92512199 0.95171124]]\n",
      "***********************************************\n",
      "iteration : 25  ::::::  [[ 0.07482117 -0.95134236]]\n",
      "######## output ######### [[0.92517883 0.95134236]]\n",
      "***********************************************\n",
      "iteration : 26  ::::::  [[ 0.07476452 -0.95096831]]\n",
      "######## output ######### [[0.92523548 0.95096831]]\n",
      "***********************************************\n",
      "iteration : 27  ::::::  [[ 0.07470806 -0.95058898]]\n",
      "######## output ######### [[0.92529194 0.95058898]]\n",
      "***********************************************\n",
      "iteration : 28  ::::::  [[ 0.0746518  -0.95020427]]\n",
      "######## output ######### [[0.9253482  0.95020427]]\n",
      "***********************************************\n",
      "iteration : 29  ::::::  [[ 0.07459572 -0.94981406]]\n",
      "######## output ######### [[0.92540428 0.94981406]]\n",
      "***********************************************\n",
      "iteration : 30  ::::::  [[ 0.07453984 -0.94941826]]\n",
      "######## output ######### [[0.92546016 0.94941826]]\n",
      "***********************************************\n",
      "iteration : 31  ::::::  [[ 0.07448414 -0.94901675]]\n",
      "######## output ######### [[0.92551586 0.94901675]]\n",
      "***********************************************\n",
      "iteration : 32  ::::::  [[ 0.07442864 -0.94860941]]\n",
      "######## output ######### [[0.92557136 0.94860941]]\n",
      "***********************************************\n",
      "iteration : 33  ::::::  [[ 0.07437332 -0.94819612]]\n",
      "######## output ######### [[0.92562668 0.94819612]]\n",
      "***********************************************\n",
      "iteration : 34  ::::::  [[ 0.0743182  -0.94777676]]\n",
      "######## output ######### [[0.9256818  0.94777676]]\n",
      "***********************************************\n",
      "iteration : 35  ::::::  [[ 0.07426326 -0.94735121]]\n",
      "######## output ######### [[0.92573674 0.94735121]]\n",
      "***********************************************\n",
      "iteration : 36  ::::::  [[ 0.07420852 -0.94691934]]\n",
      "######## output ######### [[0.92579148 0.94691934]]\n",
      "***********************************************\n",
      "iteration : 37  ::::::  [[ 0.07415396 -0.94648101]]\n",
      "######## output ######### [[0.92584604 0.94648101]]\n",
      "***********************************************\n",
      "iteration : 38  ::::::  [[ 0.07409959 -0.9460361 ]]\n",
      "######## output ######### [[0.92590041 0.9460361 ]]\n",
      "***********************************************\n",
      "iteration : 39  ::::::  [[ 0.07404541 -0.94558446]]\n",
      "######## output ######### [[0.92595459 0.94558446]]\n",
      "***********************************************\n",
      "iteration : 40  ::::::  [[ 0.07399142 -0.94512595]]\n",
      "######## output ######### [[0.92600858 0.94512595]]\n",
      "***********************************************\n",
      "iteration : 41  ::::::  [[ 0.07393762 -0.94466042]]\n",
      "######## output ######### [[0.92606238 0.94466042]]\n",
      "***********************************************\n",
      "iteration : 42  ::::::  [[ 0.07388401 -0.94418773]]\n",
      "######## output ######### [[0.92611599 0.94418773]]\n",
      "***********************************************\n",
      "iteration : 43  ::::::  [[ 0.07383058 -0.94370773]]\n",
      "######## output ######### [[0.92616942 0.94370773]]\n",
      "***********************************************\n",
      "iteration : 44  ::::::  [[ 0.07377735 -0.94322024]]\n",
      "######## output ######### [[0.92622265 0.94322024]]\n",
      "***********************************************\n",
      "iteration : 45  ::::::  [[ 0.0737243  -0.94272512]]\n",
      "######## output ######### [[0.9262757  0.94272512]]\n",
      "***********************************************\n",
      "iteration : 46  ::::::  [[ 0.07367144 -0.9422222 ]]\n",
      "######## output ######### [[0.92632856 0.9422222 ]]\n",
      "***********************************************\n",
      "iteration : 47  ::::::  [[ 0.07361876 -0.9417113 ]]\n",
      "######## output ######### [[0.92638124 0.9417113 ]]\n",
      "***********************************************\n",
      "iteration : 48  ::::::  [[ 0.07356628 -0.94119225]]\n",
      "######## output ######### [[0.92643372 0.94119225]]\n",
      "***********************************************\n",
      "iteration : 49  ::::::  [[ 0.07351398 -0.94066486]]\n",
      "######## output ######### [[0.92648602 0.94066486]]\n",
      "***********************************************\n",
      "iteration : 5951  ::::::  [[ 0.0208731  -0.02244749]]\n",
      "######## output ######### [[0.9791269  0.02244749]]\n",
      "***********************************************\n",
      "iteration : 5952  ::::::  [[ 0.02087142 -0.02244541]]\n",
      "######## output ######### [[0.97912858 0.02244541]]\n",
      "***********************************************\n",
      "iteration : 5953  ::::::  [[ 0.02086974 -0.02244334]]\n",
      "######## output ######### [[0.97913026 0.02244334]]\n",
      "***********************************************\n",
      "iteration : 5954  ::::::  [[ 0.02086807 -0.02244126]]\n",
      "######## output ######### [[0.97913193 0.02244126]]\n",
      "***********************************************\n",
      "iteration : 5955  ::::::  [[ 0.02086639 -0.02243918]]\n",
      "######## output ######### [[0.97913361 0.02243918]]\n",
      "***********************************************\n",
      "iteration : 5956  ::::::  [[ 0.02086471 -0.02243711]]\n",
      "######## output ######### [[0.97913529 0.02243711]]\n",
      "***********************************************\n",
      "iteration : 5957  ::::::  [[ 0.02086304 -0.02243503]]\n",
      "######## output ######### [[0.97913696 0.02243503]]\n",
      "***********************************************\n",
      "iteration : 5958  ::::::  [[ 0.02086136 -0.02243296]]\n",
      "######## output ######### [[0.97913864 0.02243296]]\n",
      "***********************************************\n",
      "iteration : 5959  ::::::  [[ 0.02085969 -0.02243089]]\n",
      "######## output ######### [[0.97914031 0.02243089]]\n",
      "***********************************************\n",
      "iteration : 5960  ::::::  [[ 0.02085802 -0.02242881]]\n",
      "######## output ######### [[0.97914198 0.02242881]]\n",
      "***********************************************\n",
      "iteration : 5961  ::::::  [[ 0.02085634 -0.02242674]]\n",
      "######## output ######### [[0.97914366 0.02242674]]\n",
      "***********************************************\n",
      "iteration : 5962  ::::::  [[ 0.02085467 -0.02242467]]\n",
      "######## output ######### [[0.97914533 0.02242467]]\n",
      "***********************************************\n",
      "iteration : 5963  ::::::  [[ 0.020853  -0.0224226]]\n",
      "######## output ######### [[0.979147  0.0224226]]\n",
      "***********************************************\n",
      "iteration : 5964  ::::::  [[ 0.02085132 -0.02242053]]\n",
      "######## output ######### [[0.97914868 0.02242053]]\n",
      "***********************************************\n",
      "iteration : 5965  ::::::  [[ 0.02084965 -0.02241846]]\n",
      "######## output ######### [[0.97915035 0.02241846]]\n",
      "***********************************************\n",
      "iteration : 5966  ::::::  [[ 0.02084798 -0.02241639]]\n",
      "######## output ######### [[0.97915202 0.02241639]]\n",
      "***********************************************\n",
      "iteration : 5967  ::::::  [[ 0.02084631 -0.02241432]]\n",
      "######## output ######### [[0.97915369 0.02241432]]\n",
      "***********************************************\n",
      "iteration : 5968  ::::::  [[ 0.02084464 -0.02241225]]\n",
      "######## output ######### [[0.97915536 0.02241225]]\n",
      "***********************************************\n",
      "iteration : 5969  ::::::  [[ 0.02084297 -0.02241018]]\n",
      "######## output ######### [[0.97915703 0.02241018]]\n",
      "***********************************************\n",
      "iteration : 5970  ::::::  [[ 0.0208413  -0.02240812]]\n",
      "######## output ######### [[0.9791587  0.02240812]]\n",
      "***********************************************\n",
      "iteration : 5971  ::::::  [[ 0.02083963 -0.02240605]]\n",
      "######## output ######### [[0.97916037 0.02240605]]\n",
      "***********************************************\n",
      "iteration : 5972  ::::::  [[ 0.02083796 -0.02240398]]\n",
      "######## output ######### [[0.97916204 0.02240398]]\n",
      "***********************************************\n",
      "iteration : 5973  ::::::  [[ 0.02083629 -0.02240192]]\n",
      "######## output ######### [[0.97916371 0.02240192]]\n",
      "***********************************************\n",
      "iteration : 5974  ::::::  [[ 0.02083462 -0.02239985]]\n",
      "######## output ######### [[0.97916538 0.02239985]]\n",
      "***********************************************\n",
      "iteration : 5975  ::::::  [[ 0.02083295 -0.02239779]]\n",
      "######## output ######### [[0.97916705 0.02239779]]\n",
      "***********************************************\n",
      "iteration : 5976  ::::::  [[ 0.02083128 -0.02239572]]\n",
      "######## output ######### [[0.97916872 0.02239572]]\n",
      "***********************************************\n",
      "iteration : 5977  ::::::  [[ 0.02082962 -0.02239366]]\n",
      "######## output ######### [[0.97917038 0.02239366]]\n",
      "***********************************************\n",
      "iteration : 5978  ::::::  [[ 0.02082795 -0.0223916 ]]\n",
      "######## output ######### [[0.97917205 0.0223916 ]]\n",
      "***********************************************\n",
      "iteration : 5979  ::::::  [[ 0.02082628 -0.02238953]]\n",
      "######## output ######### [[0.97917372 0.02238953]]\n",
      "***********************************************\n",
      "iteration : 5980  ::::::  [[ 0.02082462 -0.02238747]]\n",
      "######## output ######### [[0.97917538 0.02238747]]\n",
      "***********************************************\n",
      "iteration : 5981  ::::::  [[ 0.02082295 -0.02238541]]\n",
      "######## output ######### [[0.97917705 0.02238541]]\n",
      "***********************************************\n",
      "iteration : 5982  ::::::  [[ 0.02082129 -0.02238335]]\n",
      "######## output ######### [[0.97917871 0.02238335]]\n",
      "***********************************************\n",
      "iteration : 5983  ::::::  [[ 0.02081962 -0.02238129]]\n",
      "######## output ######### [[0.97918038 0.02238129]]\n",
      "***********************************************\n",
      "iteration : 5984  ::::::  [[ 0.02081796 -0.02237923]]\n",
      "######## output ######### [[0.97918204 0.02237923]]\n",
      "***********************************************\n",
      "iteration : 5985  ::::::  [[ 0.02081629 -0.02237717]]\n",
      "######## output ######### [[0.97918371 0.02237717]]\n",
      "***********************************************\n",
      "iteration : 5986  ::::::  [[ 0.02081463 -0.02237511]]\n",
      "######## output ######### [[0.97918537 0.02237511]]\n",
      "***********************************************\n",
      "iteration : 5987  ::::::  [[ 0.02081297 -0.02237306]]\n",
      "######## output ######### [[0.97918703 0.02237306]]\n",
      "***********************************************\n",
      "iteration : 5988  ::::::  [[ 0.0208113 -0.022371 ]]\n",
      "######## output ######### [[0.9791887 0.022371 ]]\n",
      "***********************************************\n",
      "iteration : 5989  ::::::  [[ 0.02080964 -0.02236894]]\n",
      "######## output ######### [[0.97919036 0.02236894]]\n",
      "***********************************************\n",
      "iteration : 5990  ::::::  [[ 0.02080798 -0.02236689]]\n",
      "######## output ######### [[0.97919202 0.02236689]]\n",
      "***********************************************\n",
      "iteration : 5991  ::::::  [[ 0.02080632 -0.02236483]]\n",
      "######## output ######### [[0.97919368 0.02236483]]\n",
      "***********************************************\n",
      "iteration : 5992  ::::::  [[ 0.02080465 -0.02236278]]\n",
      "######## output ######### [[0.97919535 0.02236278]]\n",
      "***********************************************\n",
      "iteration : 5993  ::::::  [[ 0.02080299 -0.02236072]]\n",
      "######## output ######### [[0.97919701 0.02236072]]\n",
      "***********************************************\n",
      "iteration : 5994  ::::::  [[ 0.02080133 -0.02235867]]\n",
      "######## output ######### [[0.97919867 0.02235867]]\n",
      "***********************************************\n",
      "iteration : 5995  ::::::  [[ 0.02079967 -0.02235661]]\n",
      "######## output ######### [[0.97920033 0.02235661]]\n",
      "***********************************************\n",
      "iteration : 5996  ::::::  [[ 0.02079801 -0.02235456]]\n",
      "######## output ######### [[0.97920199 0.02235456]]\n",
      "***********************************************\n",
      "iteration : 5997  ::::::  [[ 0.02079635 -0.02235251]]\n",
      "######## output ######### [[0.97920365 0.02235251]]\n",
      "***********************************************\n",
      "iteration : 5998  ::::::  [[ 0.02079469 -0.02235046]]\n",
      "######## output ######### [[0.97920531 0.02235046]]\n",
      "***********************************************\n",
      "iteration : 5999  ::::::  [[ 0.02079303 -0.02234841]]\n",
      "######## output ######### [[0.97920697 0.02234841]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "def sigmoid (layer):\n",
    "    return 1 / (1 + np.exp(-layer))\n",
    "\n",
    "def gradient(layer):\n",
    "    return layer * (1 - layer)\n",
    "    \n",
    "ipNeurons = 2\n",
    "hiddenLayerNeurons = 4\n",
    "opNeurons = 2\n",
    "iterations = 6000\n",
    "\n",
    "ip = np.random.randint(1,5,ipNeurons)\n",
    "op = np.array([1.0,0.0])\n",
    "hidden_layer = np.random.rand(1, hiddenLayerNeurons)\n",
    "\n",
    "hidden_bias = np.random.rand(1, hiddenLayerNeurons)\n",
    "op_bias = np.random.rand(1, opNeurons)\n",
    "hidden_weights = np.random.rand(ipNeurons, hiddenLayerNeurons)\n",
    "op_weights = np.random.rand(hiddenLayerNeurons, opNeurons)\n",
    "\n",
    "for i in range(iterations):\n",
    "    hidden_layer = np.dot(ip, hidden_weights)\n",
    "    hidden_layer = sigmoid(hidden_layer + hidden_bias)\n",
    "    output_layer = np.dot(hidden_layer, op_weights)\n",
    "    output_layer = sigmoid(output_layer + op_bias)\n",
    "\n",
    "    error = (op - output_layer)\n",
    "    gradient_op_layer = gradient(output_layer)\n",
    "    error_terms_output = gradient_op_layer * error\n",
    "    error_terms_hidden = gradient(hidden_layer) * np.dot(error_terms_output, op_weights.T)\n",
    "\n",
    "    gradient_hidden_weights = np.dot(ip.reshape(ipNeurons, 1), error_terms_hidden.reshape(1, hiddenLayerNeurons))\n",
    "    gradient_output_weights = np.dot(hidden_layer.reshape(hiddenLayerNeurons, 1), error_terms_output.reshape(1, opNeurons))\n",
    "    \n",
    "    hidden_weights = hidden_weights + 0.05 * gradient_hidden_weights\n",
    "    op_weights = op_weights + 0.05 * gradient_output_weights\n",
    "\n",
    "    if i < 50 or i > iterations - 50:\n",
    "        print('***********************************************')\n",
    "        print('iteration :',i,' :::::: ', error)\n",
    "        print('######## output #########', output_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
