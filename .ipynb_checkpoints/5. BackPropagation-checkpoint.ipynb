{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4da963c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************\n",
      "iteration: 0 :::: [[ 0.06492604 -0.96110633]]\n",
      "###output######## [[0.93507396 0.96110633]]\n",
      "**********************\n",
      "iteration: 1 :::: [[ 0.06490045 -0.96086899]]\n",
      "###output######## [[0.93509955 0.96086899]]\n",
      "**********************\n",
      "iteration: 2 :::: [[ 0.06487501 -0.96062898]]\n",
      "###output######## [[0.93512499 0.96062898]]\n",
      "**********************\n",
      "iteration: 3 :::: [[ 0.0648497  -0.96038626]]\n",
      "###output######## [[0.9351503  0.96038626]]\n",
      "**********************\n",
      "iteration: 4 :::: [[ 0.06482455 -0.96014077]]\n",
      "###output######## [[0.93517545 0.96014077]]\n",
      "**********************\n",
      "iteration: 5 :::: [[ 0.06479953 -0.95989248]]\n",
      "###output######## [[0.93520047 0.95989248]]\n",
      "**********************\n",
      "iteration: 6 :::: [[ 0.06477466 -0.95964135]]\n",
      "###output######## [[0.93522534 0.95964135]]\n",
      "**********************\n",
      "iteration: 7 :::: [[ 0.06474993 -0.95938731]]\n",
      "###output######## [[0.93525007 0.95938731]]\n",
      "**********************\n",
      "iteration: 8 :::: [[ 0.06472535 -0.95913034]]\n",
      "###output######## [[0.93527465 0.95913034]]\n",
      "**********************\n",
      "iteration: 9 :::: [[ 0.06470092 -0.95887037]]\n",
      "###output######## [[0.93529908 0.95887037]]\n",
      "**********************\n",
      "iteration: 10 :::: [[ 0.06467663 -0.95860736]]\n",
      "###output######## [[0.93532337 0.95860736]]\n",
      "**********************\n",
      "iteration: 11 :::: [[ 0.06465249 -0.95834126]]\n",
      "###output######## [[0.93534751 0.95834126]]\n",
      "**********************\n",
      "iteration: 12 :::: [[ 0.0646285  -0.95807202]]\n",
      "###output######## [[0.9353715  0.95807202]]\n",
      "**********************\n",
      "iteration: 13 :::: [[ 0.06460466 -0.95779959]]\n",
      "###output######## [[0.93539534 0.95779959]]\n",
      "**********************\n",
      "iteration: 14 :::: [[ 0.06458097 -0.95752391]]\n",
      "###output######## [[0.93541903 0.95752391]]\n",
      "**********************\n",
      "iteration: 15 :::: [[ 0.06455743 -0.95724492]]\n",
      "###output######## [[0.93544257 0.95724492]]\n",
      "**********************\n",
      "iteration: 16 :::: [[ 0.06453404 -0.95696258]]\n",
      "###output######## [[0.93546596 0.95696258]]\n",
      "**********************\n",
      "iteration: 17 :::: [[ 0.06451081 -0.95667682]]\n",
      "###output######## [[0.93548919 0.95667682]]\n",
      "**********************\n",
      "iteration: 18 :::: [[ 0.06448773 -0.95638759]]\n",
      "###output######## [[0.93551227 0.95638759]]\n",
      "**********************\n",
      "iteration: 19 :::: [[ 0.0644648  -0.95609483]]\n",
      "###output######## [[0.9355352  0.95609483]]\n",
      "**********************\n",
      "iteration: 20 :::: [[ 0.06444203 -0.95579847]]\n",
      "###output######## [[0.93555797 0.95579847]]\n",
      "**********************\n",
      "iteration: 21 :::: [[ 0.06441941 -0.95549845]]\n",
      "###output######## [[0.93558059 0.95549845]]\n",
      "**********************\n",
      "iteration: 22 :::: [[ 0.06439695 -0.95519472]]\n",
      "###output######## [[0.93560305 0.95519472]]\n",
      "**********************\n",
      "iteration: 23 :::: [[ 0.06437465 -0.9548872 ]]\n",
      "###output######## [[0.93562535 0.9548872 ]]\n",
      "**********************\n",
      "iteration: 24 :::: [[ 0.0643525  -0.95457583]]\n",
      "###output######## [[0.9356475  0.95457583]]\n",
      "**********************\n",
      "iteration: 25 :::: [[ 0.06433052 -0.95426054]]\n",
      "###output######## [[0.93566948 0.95426054]]\n",
      "**********************\n",
      "iteration: 26 :::: [[ 0.06430869 -0.95394127]]\n",
      "###output######## [[0.93569131 0.95394127]]\n",
      "**********************\n",
      "iteration: 27 :::: [[ 0.06428703 -0.95361794]]\n",
      "###output######## [[0.93571297 0.95361794]]\n",
      "**********************\n",
      "iteration: 28 :::: [[ 0.06426553 -0.95329047]]\n",
      "###output######## [[0.93573447 0.95329047]]\n",
      "**********************\n",
      "iteration: 29 :::: [[ 0.0642442 -0.9529588]]\n",
      "###output######## [[0.9357558 0.9529588]]\n",
      "**********************\n",
      "iteration: 30 :::: [[ 0.06422302 -0.95262285]]\n",
      "###output######## [[0.93577698 0.95262285]]\n",
      "**********************\n",
      "iteration: 31 :::: [[ 0.06420202 -0.95228255]]\n",
      "###output######## [[0.93579798 0.95228255]]\n",
      "**********************\n",
      "iteration: 32 :::: [[ 0.06418118 -0.9519378 ]]\n",
      "###output######## [[0.93581882 0.9519378 ]]\n",
      "**********************\n",
      "iteration: 33 :::: [[ 0.0641605  -0.95158854]]\n",
      "###output######## [[0.9358395  0.95158854]]\n",
      "**********************\n",
      "iteration: 34 :::: [[ 0.06414    -0.95123468]]\n",
      "###output######## [[0.93586    0.95123468]]\n",
      "**********************\n",
      "iteration: 35 :::: [[ 0.06411966 -0.95087613]]\n",
      "###output######## [[0.93588034 0.95087613]]\n",
      "**********************\n",
      "iteration: 36 :::: [[ 0.0640995  -0.95051281]]\n",
      "###output######## [[0.9359005  0.95051281]]\n",
      "**********************\n",
      "iteration: 37 :::: [[ 0.06407951 -0.95014463]]\n",
      "###output######## [[0.93592049 0.95014463]]\n",
      "**********************\n",
      "iteration: 38 :::: [[ 0.06405969 -0.9497715 ]]\n",
      "###output######## [[0.93594031 0.9497715 ]]\n",
      "**********************\n",
      "iteration: 39 :::: [[ 0.06404005 -0.94939333]]\n",
      "###output######## [[0.93595995 0.94939333]]\n",
      "**********************\n",
      "iteration: 40 :::: [[ 0.06402058 -0.94901001]]\n",
      "###output######## [[0.93597942 0.94901001]]\n",
      "**********************\n",
      "iteration: 41 :::: [[ 0.06400128 -0.94862146]]\n",
      "###output######## [[0.93599872 0.94862146]]\n",
      "**********************\n",
      "iteration: 42 :::: [[ 0.06398217 -0.94822757]]\n",
      "###output######## [[0.93601783 0.94822757]]\n",
      "**********************\n",
      "iteration: 43 :::: [[ 0.06396323 -0.94782825]]\n",
      "###output######## [[0.93603677 0.94782825]]\n",
      "**********************\n",
      "iteration: 44 :::: [[ 0.06394448 -0.94742338]]\n",
      "###output######## [[0.93605552 0.94742338]]\n",
      "**********************\n",
      "iteration: 45 :::: [[ 0.0639259  -0.94701287]]\n",
      "###output######## [[0.9360741  0.94701287]]\n",
      "**********************\n",
      "iteration: 46 :::: [[ 0.06390751 -0.9465966 ]]\n",
      "###output######## [[0.93609249 0.9465966 ]]\n",
      "**********************\n",
      "iteration: 47 :::: [[ 0.0638893  -0.94617445]]\n",
      "###output######## [[0.9361107  0.94617445]]\n",
      "**********************\n",
      "iteration: 48 :::: [[ 0.06387128 -0.94574633]]\n",
      "###output######## [[0.93612872 0.94574633]]\n",
      "**********************\n",
      "iteration: 49 :::: [[ 0.06385344 -0.9453121 ]]\n",
      "###output######## [[0.93614656 0.9453121 ]]\n",
      "**********************\n",
      "iteration: 5951 :::: [[ 0.0208515  -0.02316176]]\n",
      "###output######## [[0.9791485  0.02316176]]\n",
      "**********************\n",
      "iteration: 5952 :::: [[ 0.02084985 -0.02315957]]\n",
      "###output######## [[0.97915015 0.02315957]]\n",
      "**********************\n",
      "iteration: 5953 :::: [[ 0.02084819 -0.02315737]]\n",
      "###output######## [[0.97915181 0.02315737]]\n",
      "**********************\n",
      "iteration: 5954 :::: [[ 0.02084653 -0.02315517]]\n",
      "###output######## [[0.97915347 0.02315517]]\n",
      "**********************\n",
      "iteration: 5955 :::: [[ 0.02084488 -0.02315298]]\n",
      "###output######## [[0.97915512 0.02315298]]\n",
      "**********************\n",
      "iteration: 5956 :::: [[ 0.02084323 -0.02315078]]\n",
      "###output######## [[0.97915677 0.02315078]]\n",
      "**********************\n",
      "iteration: 5957 :::: [[ 0.02084157 -0.02314859]]\n",
      "###output######## [[0.97915843 0.02314859]]\n",
      "**********************\n",
      "iteration: 5958 :::: [[ 0.02083992 -0.0231464 ]]\n",
      "###output######## [[0.97916008 0.0231464 ]]\n",
      "**********************\n",
      "iteration: 5959 :::: [[ 0.02083826 -0.0231442 ]]\n",
      "###output######## [[0.97916174 0.0231442 ]]\n",
      "**********************\n",
      "iteration: 5960 :::: [[ 0.02083661 -0.02314201]]\n",
      "###output######## [[0.97916339 0.02314201]]\n",
      "**********************\n",
      "iteration: 5961 :::: [[ 0.02083496 -0.02313982]]\n",
      "###output######## [[0.97916504 0.02313982]]\n",
      "**********************\n",
      "iteration: 5962 :::: [[ 0.02083331 -0.02313763]]\n",
      "###output######## [[0.97916669 0.02313763]]\n",
      "**********************\n",
      "iteration: 5963 :::: [[ 0.02083166 -0.02313544]]\n",
      "###output######## [[0.97916834 0.02313544]]\n",
      "**********************\n",
      "iteration: 5964 :::: [[ 0.02083    -0.02313325]]\n",
      "###output######## [[0.97917    0.02313325]]\n",
      "**********************\n",
      "iteration: 5965 :::: [[ 0.02082835 -0.02313106]]\n",
      "###output######## [[0.97917165 0.02313106]]\n",
      "**********************\n",
      "iteration: 5966 :::: [[ 0.0208267  -0.02312887]]\n",
      "###output######## [[0.9791733  0.02312887]]\n",
      "**********************\n",
      "iteration: 5967 :::: [[ 0.02082505 -0.02312669]]\n",
      "###output######## [[0.97917495 0.02312669]]\n",
      "**********************\n",
      "iteration: 5968 :::: [[ 0.0208234 -0.0231245]]\n",
      "###output######## [[0.9791766 0.0231245]]\n",
      "**********************\n",
      "iteration: 5969 :::: [[ 0.02082175 -0.02312231]]\n",
      "###output######## [[0.97917825 0.02312231]]\n",
      "**********************\n",
      "iteration: 5970 :::: [[ 0.0208201  -0.02312013]]\n",
      "###output######## [[0.9791799  0.02312013]]\n",
      "**********************\n",
      "iteration: 5971 :::: [[ 0.02081846 -0.02311794]]\n",
      "###output######## [[0.97918154 0.02311794]]\n",
      "**********************\n",
      "iteration: 5972 :::: [[ 0.02081681 -0.02311576]]\n",
      "###output######## [[0.97918319 0.02311576]]\n",
      "**********************\n",
      "iteration: 5973 :::: [[ 0.02081516 -0.02311357]]\n",
      "###output######## [[0.97918484 0.02311357]]\n",
      "**********************\n",
      "iteration: 5974 :::: [[ 0.02081351 -0.02311139]]\n",
      "###output######## [[0.97918649 0.02311139]]\n",
      "**********************\n",
      "iteration: 5975 :::: [[ 0.02081186 -0.02310921]]\n",
      "###output######## [[0.97918814 0.02310921]]\n",
      "**********************\n",
      "iteration: 5976 :::: [[ 0.02081022 -0.02310702]]\n",
      "###output######## [[0.97918978 0.02310702]]\n",
      "**********************\n",
      "iteration: 5977 :::: [[ 0.02080857 -0.02310484]]\n",
      "###output######## [[0.97919143 0.02310484]]\n",
      "**********************\n",
      "iteration: 5978 :::: [[ 0.02080693 -0.02310266]]\n",
      "###output######## [[0.97919307 0.02310266]]\n",
      "**********************\n",
      "iteration: 5979 :::: [[ 0.02080528 -0.02310048]]\n",
      "###output######## [[0.97919472 0.02310048]]\n",
      "**********************\n",
      "iteration: 5980 :::: [[ 0.02080363 -0.0230983 ]]\n",
      "###output######## [[0.97919637 0.0230983 ]]\n",
      "**********************\n",
      "iteration: 5981 :::: [[ 0.02080199 -0.02309612]]\n",
      "###output######## [[0.97919801 0.02309612]]\n",
      "**********************\n",
      "iteration: 5982 :::: [[ 0.02080035 -0.02309394]]\n",
      "###output######## [[0.97919965 0.02309394]]\n",
      "**********************\n",
      "iteration: 5983 :::: [[ 0.0207987  -0.02309176]]\n",
      "###output######## [[0.9792013  0.02309176]]\n",
      "**********************\n",
      "iteration: 5984 :::: [[ 0.02079706 -0.02308959]]\n",
      "###output######## [[0.97920294 0.02308959]]\n",
      "**********************\n",
      "iteration: 5985 :::: [[ 0.02079541 -0.02308741]]\n",
      "###output######## [[0.97920459 0.02308741]]\n",
      "**********************\n",
      "iteration: 5986 :::: [[ 0.02079377 -0.02308523]]\n",
      "###output######## [[0.97920623 0.02308523]]\n",
      "**********************\n",
      "iteration: 5987 :::: [[ 0.02079213 -0.02308306]]\n",
      "###output######## [[0.97920787 0.02308306]]\n",
      "**********************\n",
      "iteration: 5988 :::: [[ 0.02079049 -0.02308088]]\n",
      "###output######## [[0.97920951 0.02308088]]\n",
      "**********************\n",
      "iteration: 5989 :::: [[ 0.02078885 -0.02307871]]\n",
      "###output######## [[0.97921115 0.02307871]]\n",
      "**********************\n",
      "iteration: 5990 :::: [[ 0.0207872  -0.02307653]]\n",
      "###output######## [[0.9792128  0.02307653]]\n",
      "**********************\n",
      "iteration: 5991 :::: [[ 0.02078556 -0.02307436]]\n",
      "###output######## [[0.97921444 0.02307436]]\n",
      "**********************\n",
      "iteration: 5992 :::: [[ 0.02078392 -0.02307219]]\n",
      "###output######## [[0.97921608 0.02307219]]\n",
      "**********************\n",
      "iteration: 5993 :::: [[ 0.02078228 -0.02307002]]\n",
      "###output######## [[0.97921772 0.02307002]]\n",
      "**********************\n",
      "iteration: 5994 :::: [[ 0.02078064 -0.02306784]]\n",
      "###output######## [[0.97921936 0.02306784]]\n",
      "**********************\n",
      "iteration: 5995 :::: [[ 0.020779   -0.02306567]]\n",
      "###output######## [[0.979221   0.02306567]]\n",
      "**********************\n",
      "iteration: 5996 :::: [[ 0.02077736 -0.0230635 ]]\n",
      "###output######## [[0.97922264 0.0230635 ]]\n",
      "**********************\n",
      "iteration: 5997 :::: [[ 0.02077572 -0.02306133]]\n",
      "###output######## [[0.97922428 0.02306133]]\n",
      "**********************\n",
      "iteration: 5998 :::: [[ 0.02077409 -0.02305916]]\n",
      "###output######## [[0.97922591 0.02305916]]\n",
      "**********************\n",
      "iteration: 5999 :::: [[ 0.02077245 -0.023057  ]]\n",
      "###output######## [[0.97922755 0.023057  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "inputNeurons=2 \n",
    "hiddenlayerNeurons=4 \n",
    "outputNeurons=2 \n",
    "iteration=6000\n",
    "\n",
    "input = np.random.randint(1,5,inputNeurons) \n",
    "output = np.array([1.0,0.0]) \n",
    "hidden_layer=np.random.rand(1,hiddenlayerNeurons)\n",
    "\n",
    "hidden_biass=np.random.rand(1,hiddenlayerNeurons) \n",
    "output_bias=np.random.rand(1,outputNeurons) \n",
    "hidden_weights=np.random.rand(inputNeurons,hiddenlayerNeurons) \n",
    "output_weights=np.random.rand(hiddenlayerNeurons,outputNeurons)\n",
    "\n",
    "def sigmoid (layer):\n",
    "    return 1/(1 + np.exp(-layer))\n",
    "\n",
    "\n",
    "def gradient(layer): \n",
    "    return layer*(1-layer)\n",
    "\n",
    "for i in range(iteration):\n",
    "\n",
    "    hidden_layer=np.dot(input,hidden_weights) \n",
    "    hidden_layer=sigmoid(hidden_layer+hidden_biass)\n",
    "\n",
    "    output_layer=np.dot(hidden_layer,output_weights) \n",
    "    output_layer=sigmoid(output_layer+output_bias)\n",
    "\n",
    "    error = (output-output_layer) \n",
    "    gradient_outputLayer=gradient(output_layer)\n",
    "    error_terms_output=gradient_outputLayer * error \n",
    "    error_terms_hidden=gradient(hidden_layer)*np.dot(error_terms_output,output_weights.T)\n",
    "\n",
    "    gradient_hidden_weights = np.dot(input.reshape(inputNeurons,1),error_terms_hidden.reshape(1,hiddenlayerNeurons))\n",
    "    gradient_ouput_weights = np.dot(hidden_layer.reshape(hiddenlayerNeurons,1),error_terms_output.reshape(1,outputNeurons))\n",
    "\n",
    "    hidden_weights = hidden_weights + 0.05*gradient_hidden_weights \n",
    "    output_weights = output_weights + 0.05*gradient_ouput_weights \n",
    "    if i<50 or i>iteration-50:\n",
    "        print(\"**********************\") \n",
    "        print(\"iteration:\",i,\"::::\",error) \n",
    "        print(\"###output########\",output_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
