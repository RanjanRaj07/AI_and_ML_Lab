{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b80f3b3-15a4-450a-9fec-911e64d9e0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#program 5 - Build an artificial neural network by implementing the back propagation algorithm and test the same using appropriate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d86813c-ba91-4b91-8968-3c84e8902c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "iteration : 0  ::::::  [[ 0.11858197 -0.86383894]]\n",
      "######## output ######### [[0.88141803 0.86383894]]\n",
      "***********************************************\n",
      "iteration : 1  ::::::  [[ 0.11852876 -0.86228486]]\n",
      "######## output ######### [[0.88147124 0.86228486]]\n",
      "***********************************************\n",
      "iteration : 2  ::::::  [[ 0.1184765  -0.86070628]]\n",
      "######## output ######### [[0.8815235  0.86070628]]\n",
      "***********************************************\n",
      "iteration : 3  ::::::  [[ 0.1184252  -0.85910282]]\n",
      "######## output ######### [[0.8815748  0.85910282]]\n",
      "***********************************************\n",
      "iteration : 4  ::::::  [[ 0.11837484 -0.85747412]]\n",
      "######## output ######### [[0.88162516 0.85747412]]\n",
      "***********************************************\n",
      "iteration : 5  ::::::  [[ 0.11832542 -0.8558198 ]]\n",
      "######## output ######### [[0.88167458 0.8558198 ]]\n",
      "***********************************************\n",
      "iteration : 6  ::::::  [[ 0.11827693 -0.85413948]]\n",
      "######## output ######### [[0.88172307 0.85413948]]\n",
      "***********************************************\n",
      "iteration : 7  ::::::  [[ 0.11822935 -0.8524328 ]]\n",
      "######## output ######### [[0.88177065 0.8524328 ]]\n",
      "***********************************************\n",
      "iteration : 8  ::::::  [[ 0.11818267 -0.85069939]]\n",
      "######## output ######### [[0.88181733 0.85069939]]\n",
      "***********************************************\n",
      "iteration : 9  ::::::  [[ 0.11813689 -0.84893887]]\n",
      "######## output ######### [[0.88186311 0.84893887]]\n",
      "***********************************************\n",
      "iteration : 10  ::::::  [[ 0.11809198 -0.84715086]]\n",
      "######## output ######### [[0.88190802 0.84715086]]\n",
      "***********************************************\n",
      "iteration : 11  ::::::  [[ 0.11804795 -0.84533501]]\n",
      "######## output ######### [[0.88195205 0.84533501]]\n",
      "***********************************************\n",
      "iteration : 12  ::::::  [[ 0.11800477 -0.84349095]]\n",
      "######## output ######### [[0.88199523 0.84349095]]\n",
      "***********************************************\n",
      "iteration : 13  ::::::  [[ 0.11796243 -0.84161831]]\n",
      "######## output ######### [[0.88203757 0.84161831]]\n",
      "***********************************************\n",
      "iteration : 14  ::::::  [[ 0.11792091 -0.83971672]]\n",
      "######## output ######### [[0.88207909 0.83971672]]\n",
      "***********************************************\n",
      "iteration : 15  ::::::  [[ 0.11788021 -0.83778584]]\n",
      "######## output ######### [[0.88211979 0.83778584]]\n",
      "***********************************************\n",
      "iteration : 16  ::::::  [[ 0.1178403  -0.83582532]]\n",
      "######## output ######### [[0.8821597  0.83582532]]\n",
      "***********************************************\n",
      "iteration : 17  ::::::  [[ 0.11780117 -0.83383479]]\n",
      "######## output ######### [[0.88219883 0.83383479]]\n",
      "***********************************************\n",
      "iteration : 18  ::::::  [[ 0.1177628  -0.83181392]]\n",
      "######## output ######### [[0.8822372  0.83181392]]\n",
      "***********************************************\n",
      "iteration : 19  ::::::  [[ 0.11772518 -0.82976238]]\n",
      "######## output ######### [[0.88227482 0.82976238]]\n",
      "***********************************************\n",
      "iteration : 20  ::::::  [[ 0.11768828 -0.82767983]]\n",
      "######## output ######### [[0.88231172 0.82767983]]\n",
      "***********************************************\n",
      "iteration : 21  ::::::  [[ 0.11765209 -0.82556596]]\n",
      "######## output ######### [[0.88234791 0.82556596]]\n",
      "***********************************************\n",
      "iteration : 22  ::::::  [[ 0.11761658 -0.82342045]]\n",
      "######## output ######### [[0.88238342 0.82342045]]\n",
      "***********************************************\n",
      "iteration : 23  ::::::  [[ 0.11758174 -0.82124299]]\n",
      "######## output ######### [[0.88241826 0.82124299]]\n",
      "***********************************************\n",
      "iteration : 24  ::::::  [[ 0.11754754 -0.8190333 ]]\n",
      "######## output ######### [[0.88245246 0.8190333 ]]\n",
      "***********************************************\n",
      "iteration : 25  ::::::  [[ 0.11751396 -0.81679108]]\n",
      "######## output ######### [[0.88248604 0.81679108]]\n",
      "***********************************************\n",
      "iteration : 26  ::::::  [[ 0.11748099 -0.81451607]]\n",
      "######## output ######### [[0.88251901 0.81451607]]\n",
      "***********************************************\n",
      "iteration : 27  ::::::  [[ 0.11744858 -0.81220801]]\n",
      "######## output ######### [[0.88255142 0.81220801]]\n",
      "***********************************************\n",
      "iteration : 28  ::::::  [[ 0.11741673 -0.80986664]]\n",
      "######## output ######### [[0.88258327 0.80986664]]\n",
      "***********************************************\n",
      "iteration : 29  ::::::  [[ 0.1173854  -0.80749175]]\n",
      "######## output ######### [[0.8826146  0.80749175]]\n",
      "***********************************************\n",
      "iteration : 30  ::::::  [[ 0.11735456 -0.80508311]]\n",
      "######## output ######### [[0.88264544 0.80508311]]\n",
      "***********************************************\n",
      "iteration : 31  ::::::  [[ 0.1173242  -0.80264051]]\n",
      "######## output ######### [[0.8826758  0.80264051]]\n",
      "***********************************************\n",
      "iteration : 32  ::::::  [[ 0.11729428 -0.80016378]]\n",
      "######## output ######### [[0.88270572 0.80016378]]\n",
      "***********************************************\n",
      "iteration : 33  ::::::  [[ 0.11726478 -0.79765275]]\n",
      "######## output ######### [[0.88273522 0.79765275]]\n",
      "***********************************************\n",
      "iteration : 34  ::::::  [[ 0.11723566 -0.79510727]]\n",
      "######## output ######### [[0.88276434 0.79510727]]\n",
      "***********************************************\n",
      "iteration : 35  ::::::  [[ 0.11720689 -0.79252721]]\n",
      "######## output ######### [[0.88279311 0.79252721]]\n",
      "***********************************************\n",
      "iteration : 36  ::::::  [[ 0.11717845 -0.78991246]]\n",
      "######## output ######### [[0.88282155 0.78991246]]\n",
      "***********************************************\n",
      "iteration : 37  ::::::  [[ 0.1171503  -0.78726294]]\n",
      "######## output ######### [[0.8828497  0.78726294]]\n",
      "***********************************************\n",
      "iteration : 38  ::::::  [[ 0.11712241 -0.78457858]]\n",
      "######## output ######### [[0.88287759 0.78457858]]\n",
      "***********************************************\n",
      "iteration : 39  ::::::  [[ 0.11709475 -0.78185934]]\n",
      "######## output ######### [[0.88290525 0.78185934]]\n",
      "***********************************************\n",
      "iteration : 40  ::::::  [[ 0.11706728 -0.7791052 ]]\n",
      "######## output ######### [[0.88293272 0.7791052 ]]\n",
      "***********************************************\n",
      "iteration : 41  ::::::  [[ 0.11703996 -0.77631617]]\n",
      "######## output ######### [[0.88296004 0.77631617]]\n",
      "***********************************************\n",
      "iteration : 42  ::::::  [[ 0.11701277 -0.77349229]]\n",
      "######## output ######### [[0.88298723 0.77349229]]\n",
      "***********************************************\n",
      "iteration : 43  ::::::  [[ 0.11698567 -0.77063362]]\n",
      "######## output ######### [[0.88301433 0.77063362]]\n",
      "***********************************************\n",
      "iteration : 44  ::::::  [[ 0.11695861 -0.76774024]]\n",
      "######## output ######### [[0.88304139 0.76774024]]\n",
      "***********************************************\n",
      "iteration : 45  ::::::  [[ 0.11693157 -0.76481228]]\n",
      "######## output ######### [[0.88306843 0.76481228]]\n",
      "***********************************************\n",
      "iteration : 46  ::::::  [[ 0.1169045  -0.76184987]]\n",
      "######## output ######### [[0.8830955  0.76184987]]\n",
      "***********************************************\n",
      "iteration : 47  ::::::  [[ 0.11687737 -0.7588532 ]]\n",
      "######## output ######### [[0.88312263 0.7588532 ]]\n",
      "***********************************************\n",
      "iteration : 48  ::::::  [[ 0.11685014 -0.75582246]]\n",
      "######## output ######### [[0.88314986 0.75582246]]\n",
      "***********************************************\n",
      "iteration : 49  ::::::  [[ 0.11682276 -0.75275791]]\n",
      "######## output ######### [[0.88317724 0.75275791]]\n",
      "***********************************************\n",
      "iteration : 5951  ::::::  [[ 0.02255992 -0.02406542]]\n",
      "######## output ######### [[0.97744008 0.02406542]]\n",
      "***********************************************\n",
      "iteration : 5952  ::::::  [[ 0.02255794 -0.02406309]]\n",
      "######## output ######### [[0.97744206 0.02406309]]\n",
      "***********************************************\n",
      "iteration : 5953  ::::::  [[ 0.02255595 -0.02406076]]\n",
      "######## output ######### [[0.97744405 0.02406076]]\n",
      "***********************************************\n",
      "iteration : 5954  ::::::  [[ 0.02255397 -0.02405844]]\n",
      "######## output ######### [[0.97744603 0.02405844]]\n",
      "***********************************************\n",
      "iteration : 5955  ::::::  [[ 0.02255198 -0.02405611]]\n",
      "######## output ######### [[0.97744802 0.02405611]]\n",
      "***********************************************\n",
      "iteration : 5956  ::::::  [[ 0.02255    -0.02405378]]\n",
      "######## output ######### [[0.97745    0.02405378]]\n",
      "***********************************************\n",
      "iteration : 5957  ::::::  [[ 0.02254802 -0.02405146]]\n",
      "######## output ######### [[0.97745198 0.02405146]]\n",
      "***********************************************\n",
      "iteration : 5958  ::::::  [[ 0.02254603 -0.02404913]]\n",
      "######## output ######### [[0.97745397 0.02404913]]\n",
      "***********************************************\n",
      "iteration : 5959  ::::::  [[ 0.02254405 -0.02404681]]\n",
      "######## output ######### [[0.97745595 0.02404681]]\n",
      "***********************************************\n",
      "iteration : 5960  ::::::  [[ 0.02254207 -0.02404448]]\n",
      "######## output ######### [[0.97745793 0.02404448]]\n",
      "***********************************************\n",
      "iteration : 5961  ::::::  [[ 0.02254009 -0.02404216]]\n",
      "######## output ######### [[0.97745991 0.02404216]]\n",
      "***********************************************\n",
      "iteration : 5962  ::::::  [[ 0.02253811 -0.02403984]]\n",
      "######## output ######### [[0.97746189 0.02403984]]\n",
      "***********************************************\n",
      "iteration : 5963  ::::::  [[ 0.02253613 -0.02403752]]\n",
      "######## output ######### [[0.97746387 0.02403752]]\n",
      "***********************************************\n",
      "iteration : 5964  ::::::  [[ 0.02253415 -0.0240352 ]]\n",
      "######## output ######### [[0.97746585 0.0240352 ]]\n",
      "***********************************************\n",
      "iteration : 5965  ::::::  [[ 0.02253217 -0.02403287]]\n",
      "######## output ######### [[0.97746783 0.02403287]]\n",
      "***********************************************\n",
      "iteration : 5966  ::::::  [[ 0.02253019 -0.02403055]]\n",
      "######## output ######### [[0.97746981 0.02403055]]\n",
      "***********************************************\n",
      "iteration : 5967  ::::::  [[ 0.02252821 -0.02402824]]\n",
      "######## output ######### [[0.97747179 0.02402824]]\n",
      "***********************************************\n",
      "iteration : 5968  ::::::  [[ 0.02252624 -0.02402592]]\n",
      "######## output ######### [[0.97747376 0.02402592]]\n",
      "***********************************************\n",
      "iteration : 5969  ::::::  [[ 0.02252426 -0.0240236 ]]\n",
      "######## output ######### [[0.97747574 0.0240236 ]]\n",
      "***********************************************\n",
      "iteration : 5970  ::::::  [[ 0.02252228 -0.02402128]]\n",
      "######## output ######### [[0.97747772 0.02402128]]\n",
      "***********************************************\n",
      "iteration : 5971  ::::::  [[ 0.02252031 -0.02401896]]\n",
      "######## output ######### [[0.97747969 0.02401896]]\n",
      "***********************************************\n",
      "iteration : 5972  ::::::  [[ 0.02251833 -0.02401665]]\n",
      "######## output ######### [[0.97748167 0.02401665]]\n",
      "***********************************************\n",
      "iteration : 5973  ::::::  [[ 0.02251636 -0.02401433]]\n",
      "######## output ######### [[0.97748364 0.02401433]]\n",
      "***********************************************\n",
      "iteration : 5974  ::::::  [[ 0.02251438 -0.02401202]]\n",
      "######## output ######### [[0.97748562 0.02401202]]\n",
      "***********************************************\n",
      "iteration : 5975  ::::::  [[ 0.02251241 -0.0240097 ]]\n",
      "######## output ######### [[0.97748759 0.0240097 ]]\n",
      "***********************************************\n",
      "iteration : 5976  ::::::  [[ 0.02251044 -0.02400739]]\n",
      "######## output ######### [[0.97748956 0.02400739]]\n",
      "***********************************************\n",
      "iteration : 5977  ::::::  [[ 0.02250846 -0.02400508]]\n",
      "######## output ######### [[0.97749154 0.02400508]]\n",
      "***********************************************\n",
      "iteration : 5978  ::::::  [[ 0.02250649 -0.02400277]]\n",
      "######## output ######### [[0.97749351 0.02400277]]\n",
      "***********************************************\n",
      "iteration : 5979  ::::::  [[ 0.02250452 -0.02400045]]\n",
      "######## output ######### [[0.97749548 0.02400045]]\n",
      "***********************************************\n",
      "iteration : 5980  ::::::  [[ 0.02250255 -0.02399814]]\n",
      "######## output ######### [[0.97749745 0.02399814]]\n",
      "***********************************************\n",
      "iteration : 5981  ::::::  [[ 0.02250058 -0.02399583]]\n",
      "######## output ######### [[0.97749942 0.02399583]]\n",
      "***********************************************\n",
      "iteration : 5982  ::::::  [[ 0.02249861 -0.02399352]]\n",
      "######## output ######### [[0.97750139 0.02399352]]\n",
      "***********************************************\n",
      "iteration : 5983  ::::::  [[ 0.02249664 -0.02399121]]\n",
      "######## output ######### [[0.97750336 0.02399121]]\n",
      "***********************************************\n",
      "iteration : 5984  ::::::  [[ 0.02249467 -0.0239889 ]]\n",
      "######## output ######### [[0.97750533 0.0239889 ]]\n",
      "***********************************************\n",
      "iteration : 5985  ::::::  [[ 0.0224927 -0.0239866]]\n",
      "######## output ######### [[0.9775073 0.0239866]]\n",
      "***********************************************\n",
      "iteration : 5986  ::::::  [[ 0.02249073 -0.02398429]]\n",
      "######## output ######### [[0.97750927 0.02398429]]\n",
      "***********************************************\n",
      "iteration : 5987  ::::::  [[ 0.02248876 -0.02398198]]\n",
      "######## output ######### [[0.97751124 0.02398198]]\n",
      "***********************************************\n",
      "iteration : 5988  ::::::  [[ 0.02248679 -0.02397968]]\n",
      "######## output ######### [[0.97751321 0.02397968]]\n",
      "***********************************************\n",
      "iteration : 5989  ::::::  [[ 0.02248483 -0.02397737]]\n",
      "######## output ######### [[0.97751517 0.02397737]]\n",
      "***********************************************\n",
      "iteration : 5990  ::::::  [[ 0.02248286 -0.02397507]]\n",
      "######## output ######### [[0.97751714 0.02397507]]\n",
      "***********************************************\n",
      "iteration : 5991  ::::::  [[ 0.02248089 -0.02397276]]\n",
      "######## output ######### [[0.97751911 0.02397276]]\n",
      "***********************************************\n",
      "iteration : 5992  ::::::  [[ 0.02247893 -0.02397046]]\n",
      "######## output ######### [[0.97752107 0.02397046]]\n",
      "***********************************************\n",
      "iteration : 5993  ::::::  [[ 0.02247696 -0.02396816]]\n",
      "######## output ######### [[0.97752304 0.02396816]]\n",
      "***********************************************\n",
      "iteration : 5994  ::::::  [[ 0.022475   -0.02396586]]\n",
      "######## output ######### [[0.977525   0.02396586]]\n",
      "***********************************************\n",
      "iteration : 5995  ::::::  [[ 0.02247304 -0.02396355]]\n",
      "######## output ######### [[0.97752696 0.02396355]]\n",
      "***********************************************\n",
      "iteration : 5996  ::::::  [[ 0.02247107 -0.02396125]]\n",
      "######## output ######### [[0.97752893 0.02396125]]\n",
      "***********************************************\n",
      "iteration : 5997  ::::::  [[ 0.02246911 -0.02395895]]\n",
      "######## output ######### [[0.97753089 0.02395895]]\n",
      "***********************************************\n",
      "iteration : 5998  ::::::  [[ 0.02246715 -0.02395665]]\n",
      "######## output ######### [[0.97753285 0.02395665]]\n",
      "***********************************************\n",
      "iteration : 5999  ::::::  [[ 0.02246518 -0.02395435]]\n",
      "######## output ######### [[0.97753482 0.02395435]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "ipNeurons = 2\n",
    "hiddenLayerNeurons = 4\n",
    "opNeurons = 2\n",
    "iterations = 6000\n",
    "\n",
    "ip = np.random.randint(1,5,ipNeurons)\n",
    "op = np.array([1.0,0.0])\n",
    "hidden_layer = np.random.rand(1, hiddenLayerNeurons)\n",
    "\n",
    "hidden_bias = np.random.rand(1, hiddenLayerNeurons)\n",
    "op_bias = np.random.rand(1, opNeurons)\n",
    "hidden_weights = np.random.rand(ipNeurons, hiddenLayerNeurons)\n",
    "op_weights = np.random.rand(hiddenLayerNeurons, opNeurons)\n",
    "\n",
    "def sigmoid (layer):\n",
    "    return 1 / (1 + np.exp(-layer))\n",
    "\n",
    "def gradient(layer):\n",
    "    return layer * (1 - layer)\n",
    "\n",
    "for i in range(iterations):\n",
    "    hidden_layer = np.dot(ip, hidden_weights)\n",
    "    hidden_layer = sigmoid(hidden_layer + hidden_bias)\n",
    "\n",
    "    output_layer = np.dot(hidden_layer, op_weights)\n",
    "    output_layer = sigmoid(output_layer + op_bias)\n",
    "\n",
    "    error = (op - output_layer)\n",
    "    gradient_op_layer = gradient(output_layer)\n",
    "    error_terms_output = gradient_op_layer * error\n",
    "    error_terms_hidden = gradient(hidden_layer) * np.dot(error_terms_output, op_weights.T)\n",
    "\n",
    "    gradient_hidden_weights = np.dot(ip.reshape(ipNeurons, 1), error_terms_hidden.reshape(1, hiddenLayerNeurons))\n",
    "    gradient_output_weights = np.dot(hidden_layer.reshape(hiddenLayerNeurons, 1), error_terms_output.reshape(1, opNeurons))\n",
    "\n",
    "    hidden_weights = hidden_weights + 0.05 * gradient_hidden_weights\n",
    "    op_weights = op_weights + 0.05 * gradient_output_weights\n",
    "\n",
    "    if i < 50 or i > iterations - 50:\n",
    "        print('***********************************************')\n",
    "        print('iteration :',i,' :::::: ', error)\n",
    "        print('######## output #########', output_layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
